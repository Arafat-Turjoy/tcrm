{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting a distribution to simulated TC winds\n",
    "\n",
    "Once we have simulated the wind swaths from a catalogue of TC events, we now want to examine what the probability of occurrence is for any given event. \n",
    "\n",
    "TCRM stores the simulated wind speed from each event at each location in the input location file, in a SQLite3 database. We can run a query on the database, and get the complete list of all events that generate high winds at a location. From that, we can demonstrate how TCRM fits an extreme value distribution to each point, to determine the return level wind speeds. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "from __future__ import print_function, division\n",
    "import os\n",
    "import io\n",
    "import sys\n",
    "\n",
    "import database\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import LogLocator, FormatStrFormatter\n",
    "from ipywidgets import interact, fixed, Dropdown, interactive\n",
    "import ipywidgets as widgets\n",
    "from Utilities.config import ConfigParser\n",
    "\n",
    "from scipy.stats import genpareto\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_context(\"poster\")\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make use of some extra functions that are maintained in a separate module (I use these for working with observed wind speed data for validation of TCRM and other applications)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from extremes import returnLevels, empReturnPeriod, returnPeriodUncertainty, gpdSelectThreshold\n",
    "from distributions import fittedPDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the configuration for the simulation. The key parts are to: \n",
    " - set the `TrackGenerator--NumSimulations` value to match what was used in your full TCRM simulation\n",
    " - set the same `Output--Path` and \n",
    " - set the same `Region--gridLimit` settings.\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configstr = \"\"\"\n",
    "[DataProcess]\n",
    "InputFile=/home/tcrm/data/Allstorms.ibtracs_wmo.v03r09.csv\n",
    "Source=IBTRACS\n",
    "StartSeason=1981\n",
    "FilterSeasons=False\n",
    "\n",
    "[Region]\n",
    "; Domain for windfield and hazard calculation\n",
    "gridLimit={'xMin':175.,'xMax':185.,'yMin':-23.0,'yMax':-13.0}\n",
    "gridSpace={'x':1.0,'y':1.0}\n",
    "gridInc={'x':1.0,'y':0.5}\n",
    "\n",
    "[TrackGenerator]\n",
    "NumSimulations=10000\n",
    "YearsPerSimulation=1\n",
    "SeasonSeed=68876543\n",
    "TrackSeed=334825\n",
    "TimeStep=1.0\n",
    "\n",
    "[Input]\n",
    "landmask = /home/tcrm/tcrm/input/landmask.nc\n",
    "mslpfile = /home/tcrm/tcrm/MSLP/slp.day.ltm.nc\n",
    "datasets = IBTRACS,LTMSLP\n",
    "\n",
    "[Output]\n",
    "Path=/media/sf_share/tcrm/fiji\n",
    "\n",
    "[Hazard]\n",
    "Years=2,5,10,20,25,50,100,200,250,500,1000,2000,2500,5000\n",
    "MinimumRecords=10\n",
    "CalculateCI=False\n",
    "\n",
    "[Logging]\n",
    "LogFile=/media/sf_share/tcrm/fiji/log/fiji.log\n",
    "LogLevel=INFO\n",
    "Verbose=False\n",
    "\n",
    "[IBTRACS]\n",
    "; Input data file settings\n",
    "url = ftp://eclipse.ncdc.noaa.gov/pub/ibtracs/v03r06/wmo/csv/Allstorms.ibtracs_wmo.v03r09.csv.gz\n",
    "path = /home/tcrm//tcrm/input/\n",
    "filename = Allstorms.ibtracs_wmo.v03r09.csv\n",
    "columns = tcserialno,season,num,skip,skip,skip,date,skip,lat,lon,skip,pressure\n",
    "fielddelimiter = ,\n",
    "numberofheadinglines = 3\n",
    "pressureunits = hPa\n",
    "lengthunits = km\n",
    "dateformat = %Y-%m-%d %H:%M:%S\n",
    "speedunits = kph\n",
    "\n",
    "[LTMSLP]\n",
    "; MSLP climatology file settings\n",
    "URL = ftp://ftp.cdc.noaa.gov/Datasets/ncep.reanalysis.derived/surface/slp.day.1981-2010.ltm.nc\n",
    "path = /home/tcrm//tcrm/MSLP\n",
    "filename = slp.day.ltm.nc\n",
    "\n",
    "[Process]\n",
    "DatFile=/media/sf_share/tcrm/fiji/process/dat/fiji.dat\n",
    "ExcludePastProcessed=False\n",
    "\"\"\"\n",
    "\n",
    "config = ConfigParser()\n",
    "config.readfp(io.BytesIO(configstr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configFile = \"/g/data/w85/TCRM_data/tcrm2.1/tcrm2.1.201805310953.ini\"\n",
    "config = ConfigParser()\n",
    "config.read(configFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputPath = config.get('Output', 'Path')\n",
    "print(outputPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we load the database, and get a list of locations that are stored in the database. This will be used to create a dropdown so you can select the locations and automatically plot the return level curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = database.HazardDatabase(configFile)\n",
    "locations = db.getLocations()\n",
    "locNameList = list(locations['locName'])\n",
    "outputPath = config.get('Output', 'Path')\n",
    "NumSimulations = config.getint('TrackGenerator', 'NumSimulations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define a number of functions to perform the data extraction, fitting routine and plotting..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "from scipy.stats import scoreatpercentile\n",
    "import lmfit\n",
    "\n",
    "def residual(p, x, y):\n",
    "    return genpareto.pdf(x, p['xi'], loc=p['mu'], scale=p['sig']) - y\n",
    "\n",
    "def calcSD(pars, cov, rate, npyr, intervals):\n",
    "    nsims = 1000\n",
    "    rps = np.zeros((nsims, len(intervals)))\n",
    "    for i in range(nsims):\n",
    "        xi = pars[0] + np.random.normal(0, np.sqrt(cov[0,0]))\n",
    "        mu = pars[1] + np.random.normal(0, np.sqrt(cov[1,1]))\n",
    "        sig = pars[2] + np.random.normal(0, np.sqrt(cov[2,2]))\n",
    "        rps[i, : ] = mu + (sig / xi) * (np.power(intervals * npyr * rate, xi) - 1.)\n",
    "\n",
    "    lowerrp = scoreatpercentile(rps, 2.5, axis=0)\n",
    "    upperrp = scoreatpercentile(rps, 97.5, axis=0)\n",
    "    return lowerrp, upperrp\n",
    "\n",
    "def calculateUncertainty(wspd, intervals, xi, mu, sig):\n",
    "    \"\"\"\n",
    "    :param wspd: :class:`numpy.array` of wind speeds\n",
    "    :param float xi: initial guess for \n",
    "    \"\"\"\n",
    "    bins = np.arange(0.5, 100, 1)\n",
    "    n, bins = np.histogram(wspd, bins, normed=True)\n",
    "    centres = 0.5*(bins[1:]+bins[:-1])\n",
    "    #pars,cov = curve_fit(lambda x, xi, mu, sig: genpareto.pdf(x, xi, loc=mu, scale=sig), \n",
    "    #                     centres, n, p0=[0, np.mean(wspd), np.mean(wspd)], maxfev=10000 )\n",
    "    gpd = genpareto.fit(wspd[wspd > mu], loc=mu)\n",
    "    npyr = 365.25\n",
    "\n",
    "    p = lmfit.Parameters()\n",
    "    p.add_many(('xi', gpd[0], True, -np.inf, 1.), ('mu', gpd[1]),('sig', gpd[2]))\n",
    "\n",
    "    mini = lmfit.Minimizer(residual, p, fcn_args=(centres, n), nan_policy='omit')\n",
    "\n",
    "    # first solve with Nelder-Mead\n",
    "    out1 = mini.minimize(method='Nelder')\n",
    "    out2 = mini.minimize(method='leastsq', params=out1.params)\n",
    "\n",
    "    cmu = out2.params['mu'].value\n",
    "    cxi = out2.params['xi'].value\n",
    "    csig = out2.params['sig'].value\n",
    "    rate = len(wspd[wspd > cmu])/(npyr*10000)\n",
    "    print(\"Rate (calcUncertainty): {0}\".format(rate))\n",
    "    crp = cmu + (csig / cxi) * (np.power(intervals * npyr * rate, cxi) - 1.)\n",
    "    lrp, urp = calcSD((cxi, cmu, csig), out2.covar, rate, npyr, intervals)\n",
    "    return crp, lrp, urp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlotUnits(object):\n",
    "\n",
    "    def __init__(self, units):\n",
    "        labels = {\n",
    "            'mps': 'm/s',\n",
    "            'mph': 'mi/h',\n",
    "            'kts': 'kts',\n",
    "            'kph': 'km/h',\n",
    "            'kmh': 'km/h'\n",
    "        }\n",
    "\n",
    "        levels = {\n",
    "            'mps': np.arange(30, 101., 5.),\n",
    "            'mph': np.arange(80, 221., 10.),\n",
    "            'kts': np.arange(60, 201., 10.),\n",
    "            'kph': np.arange(80, 361., 20.),\n",
    "            'kmh': np.arange(80, 361., 20.)\n",
    "        }\n",
    "\n",
    "        self.units = units\n",
    "        self.label = labels[units]\n",
    "        self.levels = levels[units]\n",
    "        \n",
    "# Set the plotting units to be metres/second\n",
    "plotUnits = PlotUnits('mps')\n",
    "\n",
    "def extractRecords(db, locId, nsimulations):\n",
    "    recs = database.locationRecords(db, locId)\n",
    "    data = np.zeros(int(nsimulations * 365.25))\n",
    "    data[-len(recs):] = recs['wspd']\n",
    "\n",
    "    allevents = np.sort(data)\n",
    "    return allevents\n",
    "\n",
    "def extractReturnLevel(db, locId):\n",
    "    recs = database.locationAllReturnLevels(db, locId)\n",
    "    return recs\n",
    "\n",
    "def fitDistribution(db, locId, intervals, nyears):\n",
    "    records = database.locationRecords(db, locId)\n",
    "    recs = records['wspd'][records['wspd'] > 0]\n",
    "    threshold = np.percentile(recs, 99.5)\n",
    "    gpd = genpareto.fit(recs[recs > threshold], loc=threshold)\n",
    "    print(gpd)\n",
    "    data = np.zeros(int(nyears*365.25))\n",
    "    data[-len(recs):] = recs\n",
    "    rate = float(len(data[data > threshold])) / float(len(data))\n",
    "    print(\"Rate (fitDistribution): {0}\".format(rate))\n",
    "    rval = returnLevels(intervals, threshold, gpd[0], gpd[2], rate)\n",
    "    crp, lrp, urp = calculateUncertainty(recs, intervals, gpd[0], gpd[1], gpd[2])\n",
    "    print(crp)\n",
    "    return crp, lrp, urp\n",
    "\n",
    "def addGrid(axes):\n",
    "    \"\"\"\n",
    "    Add a logarithmic graticule to the subplot axes.\n",
    "    :param axes: :class:`axes` instance.\n",
    "    \"\"\"\n",
    "\n",
    "    axes.xaxis.set_major_locator(LogLocator())\n",
    "    axes.xaxis.set_major_formatter(FormatStrFormatter('%d'))\n",
    "    axes.xaxis.set_minor_locator(LogLocator(subs=[.1, .2, .3, .4, .5, .6, .7, .8, .9]))\n",
    "    axes.autoscale(True, axis='x', tight=True)\n",
    "    axes.grid(True, which='major', linestyle='-', linewidth=0.5)\n",
    "    axes.grid(True, which='minor', linestyle='-', linewidth=0.5)\n",
    "    \n",
    "def subplot(axes, subfigure):\n",
    "    \"\"\"\n",
    "    Draw a line and range plot on an :class:`matplotlib.axes`\n",
    "    instance, with a logarithmic scale on the x-axis. Data and\n",
    "    labels are contained in a tuple. x-ticks presented as integer\n",
    "    values. A grid is added with a call to\n",
    "    :meth:`SemilogCurve.addGrid`.\n",
    "    :param axes: :class:`matplotlib.axes` instance.\n",
    "    :param tuple subfigure: Holds the data and labels to be added\n",
    "                            to the subplot.\n",
    "    \"\"\"\n",
    "    xdata, events, ydata, xlabel, ylabel, title, fit = subfigure\n",
    "    rp, lrp, urp = ydata\n",
    "    emprp = empReturnPeriod(events)\n",
    "\n",
    "    axes.semilogx(xdata, rp, lw=2, subsx=xdata, \n",
    "                  label = 'Fitted hazard curve ({0})'.format(fit))\n",
    "    axes.scatter(emprp[emprp > 1], events[emprp > 1], s=100,\n",
    "                 color='r', label = 'Empirical ARI')\n",
    "    axes.semilogx(xdata, lrp, lw=2, color='0.5', linestyle='--', subsx=xdata)\n",
    "    axes.semilogx(xdata, urp, lw=2, color='0.5', linestyle='--', subsx=xdata, label=\"90% CI\")\n",
    "\n",
    "    axes.legend(loc = 2)\n",
    "\n",
    "    axes.set_xlabel(xlabel)\n",
    "    axes.set_ylabel(ylabel)\n",
    "    axes.set_title(title)\n",
    "    ylim = (0., np.max([100, np.ceil(rp.max()/10.)*10.]))\n",
    "    axes.set_ylim(ylim)\n",
    "    addGrid(axes)\n",
    "    return axes\n",
    "    \n",
    "def plot(years, events, rlevel, locName, locLon, locLat, fit):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "    xlabel = 'Average recurrence interval (years)'\n",
    "    ylabel = 'Wind speed (%s)'%plotUnits.label\n",
    "    title = \"Return period wind speeds at \" + locName + \", \\n(%5.1f,%5.1f)\"%(locLon, locLat)\n",
    "    subfigure = (years, events, rlevel, xlabel, ylabel, title, fit)\n",
    "    ax = subplot(ax, subfigure)\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def plotLocation(locName):\n",
    "    years = np.array(config.get('Hazard', 'Years').split(',')).astype(float)\n",
    "    locId = locations['locId'][locations['locName']==locName][0]\n",
    "    events = extractRecords(db, locId, NumSimulations)\n",
    "    rlevel = fitDistribution(db, locId, years, NumSimulations)\n",
    "    locLon = locations['locLon'][locations['locId']==locId][0]\n",
    "    locLat = locations['locLat'][locations['locId']==locId][0]\n",
    "    plot(years, events, rlevel, locName, locLon, locLat, 'GPD')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive(plotLocation, \n",
    "            locName=Dropdown(options=locNameList, description=\"Location\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processCI(locName, percentile=99.):\n",
    "    locId = locations['locId'][locations['locName']==locName][0]\n",
    "    recs = database.locationRecords(db, locId)\n",
    "    wspd = recs['wspd'][recs['wspd']>0]\n",
    "    print(\"Number of records > 0: {0}\".format(len(wspd[wspd > 0])))\n",
    "    data = np.zeros(365.25*10000)\n",
    "    data[-len(wspd):] = wspd\n",
    "    emprp = empReturnPeriod(data)\n",
    "    threshold = np.percentile(wspd[wspd > 0], percentile)\n",
    "    gpd = genpareto.fit(wspd[wspd > threshold], loc=threshold)\n",
    "\n",
    "    print(threshold)\n",
    "    print(gpd)\n",
    "    print(\"No. exceedances: {0}\".format(len(wspd[wspd > gpd[1]])))\n",
    "    years = np.array(config.get('Hazard', 'Years').split(',')).astype(float)\n",
    "    crp, lrp, urp = calculateUncertainty(wspd[wspd > threshold], years, *gpd)\n",
    "    print(crp)\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    ax.semilogx(years, crp)\n",
    "    ax.semilogx(years, lrp, '0.5')\n",
    "    ax.semilogx(years, urp, '0.5')\n",
    "    ax.scatter(emprp[emprp > 1], data[emprp > 1], s=100,\n",
    "                     color='r', label = 'Empirical ARI')\n",
    "    addGrid(ax)\n",
    "    ax.set_ylim((0, 100))\n",
    "    ax.set_title(\"{0}\".format(locName))\n",
    "    \n",
    "    fmt = ['%d', '%.3f', '%.3f','%.3f']\n",
    "    hdr = 'ARI,lower,mean,upper'\n",
    "    fname = '{0:d}.csv'.format(locId)\n",
    "    np.savetxt(fname, np.vstack([years, lrp, crp, urp]).T, fmt=fmt, delimiter=',', header=hdr)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processCI(\"Darwin Airport\", 99.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locList = ['Carnarvon Airport','Learmonth Airport','Port Hedland Airport', 'Broome Airport',\n",
    "           'Darwin Airport', 'Gove Airport', 'Cairns Airport',\n",
    "           'Townsville Amo',]# 'Brisbane Airport M. O']\n",
    "\n",
    "for loc in locList:\n",
    "    print(loc)\n",
    "    processCI(loc, 99.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "\n",
    "def residual2(p, x, y):\n",
    "    f = p['a'] - p['b'] * np.power(x, p['c'])\n",
    "    return f - y\n",
    "\n",
    "locName = \"Carnarvon Airport\"\n",
    "locId = locations['locId'][locations['locName']==locName][0]\n",
    "events = extractRecords(db, locId, NumSimulations)\n",
    "emprp = empReturnPeriod(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wspd = events[events > 0]\n",
    "emprp = emprp[events > 0]\n",
    "idx = np.where(wspd > np.median(wspd))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pars,cov = curve_fit(lambda x, a, b, c: a - b * np.power(x, c), \n",
    "                     emprp[idx], wspd[idx], \n",
    "                     p0=[np.max(wspd), \n",
    "                         np.max(wspd), -0.1], \n",
    "                     maxfev=10000 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2 = lmfit.Parameters()\n",
    "p2.add_many(('a', pars[0], True, 0, np.inf), \n",
    "            ('b', pars[1], True, 0, np.inf),\n",
    "            ('c', pars[2], True, -np.inf, -0.01))\n",
    "\n",
    "mini2 = lmfit.Minimizer(residual2, p2, fcn_args=(emprp[idx], wspd[idx]), nan_policy='omit')\n",
    "\n",
    "    # first solve with Nelder-Mead\n",
    "out21 = mini2.minimize(method='Nelder')\n",
    "out22 = mini2.minimize(method='leastsq', params=out21.params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calcSD2(pars, cov, intervals):\n",
    "    nsims = 1000\n",
    "    rps = np.zeros((nsims, len(intervals)))\n",
    "    for i in range(nsims):\n",
    "        xi = pars[0] + np.random.normal(0, np.sqrt(cov[0,0]))\n",
    "        mu = pars[1] + np.random.normal(0, np.sqrt(cov[1,1]))\n",
    "        sig = pars[2] + np.random.normal(0, np.sqrt(cov[2,2]))\n",
    "        rps[i, : ] = xi - mu * np.power(intervals, sig)\n",
    "\n",
    "    lowerrp = scoreatpercentile(rps, .5, axis=0)\n",
    "    upperrp = scoreatpercentile(rps, 99.5, axis=0)\n",
    "    return lowerrp, upperrp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = out22.params['a'].value\n",
    "b = out22.params['b'].value\n",
    "c = out22.params['c'].value\n",
    "x = np.arange(1, 10001)\n",
    "y = a - b * np.power(x, c)\n",
    "yl, yu = calcSD2([a, b, c], out22.covar, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "plt.semilogx(x, y)\n",
    "plt.semilogx(x, yl, linestyle='--', color='0.5')\n",
    "plt.semilogx(x, yu, linestyle='--', color='0.5')\n",
    "\n",
    "plt.scatter(emprp, wspd)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = wspd\n",
    "n=len(w)/10000.\n",
    "cdf = 1 - np.power((1./n)*(np.power((a-w)/b,(1/c))), -1.)\n",
    "cdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "plt.plot(w, cdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
